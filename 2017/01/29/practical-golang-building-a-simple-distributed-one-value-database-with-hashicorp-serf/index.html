<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Practical Golang: Building a simple, distributed one-value database with Hashicorp Serf | Jacob Martin</title><meta name=keywords content="cluster,database,distributed,go,golang,microservice,microservices,resiliency,server,tutorial"><meta name=description content="Introduction With the advent of distributed applications, we see new storage solutions emerging constantly.
They include, but are not limited to, Cassandra, Redis, CockroachDB, Consul or RethinkDB.
Most of you probably use one, or more, of them.
They seem to be really complex systems, because they actually are. This can’t be denied.
But it’s pretty easy to write a simple, one value database, featuring high availability.
You probably wouldn’t use anything near this in production, but it should be a fruitful learning experience for you nevertheless."><meta name=author content="Jacob Martin"><link rel=canonical href=https://cube2222.github.io/2017/01/29/practical-golang-building-a-simple-distributed-one-value-database-with-hashicorp-serf/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.min.35cd0f65a15cafa92372b8313deef5960aae04b90ad722f2bbf509eb0468137e.css integrity="sha256-Nc0PZaFcr6kjcrgxPe71lgquBLkK1yLyu/UJ6wRoE34=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://cube2222.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://cube2222.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://cube2222.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://cube2222.github.io/apple-touch-icon.png><link rel=mask-icon href=https://cube2222.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.85.0"><meta property="og:title" content="Practical Golang: Building a simple, distributed one-value database with Hashicorp Serf"><meta property="og:description" content="Introduction With the advent of distributed applications, we see new storage solutions emerging constantly.
They include, but are not limited to, Cassandra, Redis, CockroachDB, Consul or RethinkDB.
Most of you probably use one, or more, of them.
They seem to be really complex systems, because they actually are. This can’t be denied.
But it’s pretty easy to write a simple, one value database, featuring high availability.
You probably wouldn’t use anything near this in production, but it should be a fruitful learning experience for you nevertheless."><meta property="og:type" content="article"><meta property="og:url" content="https://cube2222.github.io/2017/01/29/practical-golang-building-a-simple-distributed-one-value-database-with-hashicorp-serf/"><meta property="og:image" content="https://cube2222.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2017-01-29T11:24:18+00:00"><meta property="article:modified_time" content="2017-01-29T11:24:18+00:00"><meta property="og:site_name" content="Jacob Martin"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://cube2222.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Practical Golang: Building a simple, distributed one-value database with Hashicorp Serf"><meta name=twitter:description content="Introduction With the advent of distributed applications, we see new storage solutions emerging constantly.
They include, but are not limited to, Cassandra, Redis, CockroachDB, Consul or RethinkDB.
Most of you probably use one, or more, of them.
They seem to be really complex systems, because they actually are. This can’t be denied.
But it’s pretty easy to write a simple, one value database, featuring high availability.
You probably wouldn’t use anything near this in production, but it should be a fruitful learning experience for you nevertheless."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://cube2222.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Practical Golang: Building a simple, distributed one-value database with Hashicorp Serf","item":"https://cube2222.github.io/2017/01/29/practical-golang-building-a-simple-distributed-one-value-database-with-hashicorp-serf/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Practical Golang: Building a simple, distributed one-value database with Hashicorp Serf","name":"Practical Golang: Building a simple, distributed one-value database with Hashicorp Serf","description":"Introduction With the advent of distributed applications, we see new storage solutions emerging constantly.\nThey include, but are not limited to, Cassandra, Redis, CockroachDB, Consul or RethinkDB.\nMost of you probably use one, or more, of them.\nThey seem to be really complex systems, because they actually are. This can’t be denied.\nBut it’s pretty easy to write a simple, one value database, featuring high availability.\nYou probably wouldn’t use anything near this in production, but it should be a fruitful learning experience for you nevertheless.","keywords":["cluster","database","distributed","go","golang","microservice","microservices","resiliency","server","tutorial"],"articleBody":"Introduction With the advent of distributed applications, we see new storage solutions emerging constantly.\nThey include, but are not limited to, Cassandra, Redis, CockroachDB, Consul or RethinkDB.\nMost of you probably use one, or more, of them.\nThey seem to be really complex systems, because they actually are. This can’t be denied.\nBut it’s pretty easy to write a simple, one value database, featuring high availability.\nYou probably wouldn’t use anything near this in production, but it should be a fruitful learning experience for you nevertheless.\nIf you’re interested, read on!\nDependencies You’ll need to\ngo get github.com/hashicorp/serf/serf  as a key dependency.\nWe’ll also use those for convenience’s sake:\n\"github.com/gorilla/mux\" \"github.com/pkg/errors\" \"golang.org/x/sync/errgroup\"  Small overview What will we build? We’ll build a one-value clustered database. Which means, numerous instances of our application will be able to work together.\nYou’ll be able to set or get the value using a REST interface. The value will then shortly be spread across the cluster using the Gossip protocol.\nWhich means, every node tells a part of the cluster about the current state of the variable in set intervals. But because later each of those also tells a part of the cluster about the state, the whole cluster ends up having been informed shortly.\nIt’ll use Serf for easy cluster membership, which uses SWIM under the hood. SWIM is a more advanced Gossip-like algorithm, which you can read on about here.\nNow let’s get to the implementation…\nGetting started First, we’ll of course have to put in all our imports:\nFollowing this, it’s time to write a simple thread-safe, one-value store.\nAn important thing is, the database will also hold the generation of the variable. This way, when one instance gets notified about a new value, it can check if the incoming notification actually has a higher generation count. Only then, will it change the current local value.\nSo our database structure will hold exactly this: the number, generation and a mutex.\nWe’ll also need a way to set and get the value.\nSetting the value will also advance the generation count, so when we notify the rest of this cluster, we will overwrite their values and generation counts.\nFinally, we will need a way to notify the database of changes that happened elsewhere, if they have a higher generation count.\nFor that we’ll have a small notify method, which will return true, if anything has been changed:\nWe’ll also create a const describing how many nodes we will notify about the new value every time.\nNow let’s get to the actual functioning of the application. First we’ll have to start an instance of serf, using two variables. The address of our instance in the network and the -optional- address of the cluster to join.\nHow does the setupCluster function work, you may ask? Here it is:\nAs we can see, we are creating the cluster, only changing the advertise address.\nIf the creation fails, we of course return the error.\nIf the joining fails though, it means that we either didn’t get a cluster address,\nor the cluster doesn’t exist (omitting network failures), which means we can safely ignore that and just log it.\nTo continue with, we initialize the database and the REST API:\n(I’ve really chosen the number at random… really!)\nAnd this is what the API creation looks like:\nWe first asynchronously start our server. Then we declare our getter:\nour setter:\nand finally the API endpoint which allows other nodes to notify this instance of changes:\nIt’s also here where we start our server and print some debug info when getting notified of new values by other members of our cluster.\n Great, we’ve got a way to talk to our service now. Time to make it actually spread all the information.\nWe’ll also be printing debug info regularly.\nTo begin with, let’s initiate our context (that’s always a good idea in the main function).\nWe’ll also put a value into it, the name of our host, just for the debug logs.\nIt’s a good thing to put into the context, as it’s not something crucial for the functioning of our program,\nand the context will get passed further anyways.\nHaving done this, we can set up our main loop, including the intervals at which we’ll be sending state updates to peers and printing debug info.\nOk, that seems to be it.\nJust kidding. Time to finish up our service with the notification code.\nWe’ll now get a list of other members in the cluster, set a timeout, and asynchronously notify a part of those others.\nNow, let’s look at the getOtherMembers function. It’s actually just a function scanning through the memberlist, deleting ourselves and other nodes that aren’t alive at the moment.\nThere’s not much to it I suppose. It’s using slicing to cut out or cut off members not conforming to our predicates.\nFinally the function we use to notify others:\nIf there are only two members then it sends the notifications to them, otherwise it chooses a random index in the members array and chooses subsequent members from there on.\nHow does the errgroup work? It’s a nifty library Brian Ketelsen wrote a great article about. It’s basically a wait group which also gathers errors and aborts when one happens.\nNow to finish our code, the notifyMember function:\nWe craft a path with the formula {nodeAddress}:8080/notify/{curVal}/{curGen}?notifier={selfHostName}\nWe add the context to the request, so we get the timeout functionality, and finally make the request.\nAnd that’s actually all there is to the code.\nTesting our database We’ll test our database using docker. The necessary dockerfile to put into your project directory looks like this:\nNow, first build your application (if you’re not on linux, you have to set the env variables GOOS=linux and GOARCH=amd64)\nLater build the docker image:\ndocker build -t distapp .  And finally we can launch it. To supply the necessary environment variables, we’ll need to know what ip address the containers will get.\nFirst run:\ndocker network inspect bridge  Bridge is the default network containers get assigned to. You should get something like this:\n[ { \"Name\": \"bridge\", \"Id\": \"b56a19697ed9d30488f189d5517fd79f04a4df70c8bbc07d8f3c49a491f10433\", \"Created\": \"2017-01-29T10:48:05.1592086Z\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [ { \"Subnet\": \"172.17.0.0/16\", \"Gateway\": \"172.17.0.1\"  What’s important for us is the gateway. In this case, our containers would be spawned with IP addresses from 172.17.0.2\nSo now we can start a few containers:\ndocker run -e ADVERTISE_ADDR=172.17.0.2 -p 8080:8080 distapp docker run -e ADVERTISE_ADDR=172.17.0.3 -e CLUSTER_ADDR=172.17.0.2 -p 8081:8080 distapp docker run -e ADVERTISE_ADDR=172.17.0.4 -e CLUSTER_ADDR=172.17.0.3 -p 8082:8080 distapp docker run -e ADVERTISE_ADDR=172.17.0.5 -e CLUSTER_ADDR=172.17.0.4 -p 8083:8080 distapp  Next on you can test your deployment by stopping and starting containers, and setting/getting the variables at:\nlocalhost:8080/set/5 localhost:8082/get/5 etc...  Conclusion What’s important, this is a really basic distributed system, it may become inconsistent (if you update the value on two different machines simultaneously, the cluster will have two values depending on the machine).\nIf you want to learn more, read about CAP, consensus, Paxos, RAFT, gossip, and data replication, they are all very interesting topics (at least in my opinion).\nAnyways, I hope you had fun creating a small distributed system and encourage you to build your own, more advanced one, it’ll be a great learning experience for sure!\nThe whole code is available on my Github.\n","wordCount":"1261","inLanguage":"en","datePublished":"2017-01-29T11:24:18Z","dateModified":"2017-01-29T11:24:18Z","author":{"@type":"Person","name":"Jacob Martin"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://cube2222.github.io/2017/01/29/practical-golang-building-a-simple-distributed-one-value-database-with-hashicorp-serf/"},"publisher":{"@type":"Organization","name":"Jacob Martin","logo":{"@type":"ImageObject","url":"https://cube2222.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://cube2222.github.io/ accesskey=h title="Jacob Martin (Alt + H)">Jacob Martin</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://cube2222.github.io/ title="About Me"><span>About Me</span></a></li><li><a href=https://cube2222.github.io/archive title=Archive><span>Archive</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://cube2222.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://cube2222.github.io/posts/>Posts</a></div><h1 class=post-title>Practical Golang: Building a simple, distributed one-value database with Hashicorp Serf</h1><div class=post-meta>January 29, 2017&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Jacob Martin&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/2017-01-29-practical-golang-building-a-simple-distributed-one-value-database-with-hashicorp-serf.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>With the advent of <em>distributed applications</em>, we see new storage solutions emerging constantly.<br>They include, but are not limited to, <a href=https://cassandra.apache.org/>Cassandra</a>, <a href=https://redis.io/>Redis</a>, <a href=https://www.cockroachlabs.com/>CockroachDB</a>, <a href=https://www.consul.io/>Consul</a> or <a href=https://www.rethinkdb.com/>RethinkDB</a>.<br>Most of you probably use one, or more, of them.</p><p>They seem to be really complex systems, because they actually are. This can’t be denied.<br>But it’s pretty easy to write a simple, one value database, featuring <em>high availability</em>.<br>You probably wouldn’t use anything near this in production, but it should be a fruitful learning experience for you nevertheless.<br>If you’re interested, read on!</p><h2 id=dependencies>Dependencies<a hidden class=anchor aria-hidden=true href=#dependencies>#</a></h2><p>You’ll need to</p><pre><code>go get github.com/hashicorp/serf/serf
</code></pre><p>as a key dependency.</p><p>We’ll also use those for convenience’s sake:</p><pre><code>&quot;github.com/gorilla/mux&quot;
&quot;github.com/pkg/errors&quot;
&quot;golang.org/x/sync/errgroup&quot;
</code></pre><h2 id=small-overview>Small overview<a hidden class=anchor aria-hidden=true href=#small-overview>#</a></h2><p>What will we build? We’ll build a one-value <em>clustered</em> database. Which means, numerous instances of our application will be able to work together.<br>You’ll be able to set or get the value using a REST interface. The value will then shortly be spread across the cluster using the Gossip protocol.<br>Which means, every node tells a part of the cluster about the current state of the variable in set intervals. But because later each of those also tells a part of the cluster about the state, the whole cluster ends up having been informed shortly.</p><p>It’ll use Serf for easy cluster membership, which uses SWIM under the hood. SWIM is a more advanced Gossip-like algorithm, which you can read on about <a href=https://www.cs.cornell.edu/~asdas/research/dsn02-swim.pdf>here</a>.</p><p>Now let’s get to the implementation…</p><h2 id=getting-started>Getting started<a hidden class=anchor aria-hidden=true href=#getting-started>#</a></h2><p>First, we’ll of course have to put in all our imports:</p><p>Following this, it’s time to write a simple thread-safe, one-value store.<br>An important thing is, the database will also hold the <em>generation</em> of the variable. This way, when one instance gets notified about a new value, it can check if the incoming notification actually has a higher generation count. Only then, will it change the current local value.<br>So our database structure will hold exactly this: the number, generation and a mutex.</p><p>We’ll also need a way to set and get the value.<br>Setting the value will also advance the generation count, so when we notify the rest of this cluster, we will overwrite their values and generation counts.</p><p>Finally, we will need a way to notify the database of changes that happened elsewhere, if they have a higher generation count.<br>For that we’ll have a small notify method, which will return true, if anything has been changed:</p><p>We’ll also create a const describing how many nodes we will notify about the new value every time.</p><p>Now let’s get to the actual functioning of the application. First we’ll have to start an instance of serf, using two variables. The address of our instance in the network and the -optional- address of the cluster to join.</p><p>How does the setupCluster function work, you may ask? Here it is:</p><p>As we can see, we are creating the cluster, only changing the advertise address.</p><p>If the creation fails, we of course return the error.<br>If the joining fails though, it means that we either didn’t get a cluster address,<br>or the cluster doesn’t exist (omitting network failures), which means we can safely ignore that and just log it.</p><p>To continue with, we initialize the database and the REST API:<br>(I’ve really chosen the number at random… really!)</p><p>And this is what the API creation looks like:</p><p>We first asynchronously start our server. Then we declare our getter:</p><p>our setter:</p><p>and finally the API endpoint which allows other <em>nodes</em> to notify this instance of changes:</p><p>It’s also here where we start our server and print some debug info when getting notified of new values by other <em>members</em> of our cluster.</p><hr><p>Great, we’ve got a way to talk to our service now. Time to make it actually spread all the information.<br>We’ll also be printing debug info regularly.</p><p>To begin with, let’s initiate our <em>context</em> (that’s always a good idea in the main function).<br>We’ll also put a value into it, the name of our host, just for the debug logs.<br>It’s a good thing to put into the context, as it’s not something crucial for the functioning of our program,<br>and the context will get passed further anyways.</p><p>Having done this, we can set up our main loop, including the intervals at which we’ll be sending state updates to peers and printing debug info.</p><p>Ok, that seems to be it.</p><p>Just kidding. Time to finish up our service with the notification code.<br>We’ll now get a list of <strong>other</strong> members in the cluster, set a timeout, and asynchronously notify a part of those others.</p><p>Now, let’s look at the <em>getOtherMembers</em> function. It’s actually just a function scanning through the memberlist, deleting ourselves and other nodes that aren’t alive at the moment.</p><p>There’s not much to it I suppose. It’s using slicing to cut out or cut off members not conforming to our predicates.</p><p>Finally the function we use to notify others:</p><p>If there are only two members then it sends the notifications to them, otherwise it chooses a random index in the members array and chooses subsequent members from there on.<br>How does the errgroup work? It’s a nifty library Brian Ketelsen wrote a <a href=https://www.oreilly.com/learning/run-strikingly-fast-parallel-file-searches-in-go-with-sync-errgroup>great article</a> about. It’s basically a wait group which also gathers errors and aborts when one happens.</p><p>Now to finish our code, the <em>notifyMember</em> function:</p><p>We craft a path with the formula <em>{nodeAddress}:8080/notify/{curVal}/{curGen}?notifier={selfHostName}</em><br>We add the context to the request, so we get the timeout functionality, and finally make the request.</p><p>And that’s actually all there is to the code.</p><h2 id=testing-our-database>Testing our database<a hidden class=anchor aria-hidden=true href=#testing-our-database>#</a></h2><p>We’ll test our database using docker. The necessary dockerfile to put into your project directory looks like this:</p><p>Now, first build your application (if you’re not on linux, you have to set the env variables GOOS=linux and GOARCH=amd64)<br>Later build the docker image:</p><pre><code>docker build -t distapp .
</code></pre><p>And finally we can launch it. To supply the necessary environment variables, we’ll need to know what ip address the containers will get.<br>First run:</p><pre><code>docker network inspect bridge
</code></pre><p>Bridge is the default network containers get assigned to. You should get something like this:</p><pre><code>[
    {
        &quot;Name&quot;: &quot;bridge&quot;,
        &quot;Id&quot;: &quot;b56a19697ed9d30488f189d5517fd79f04a4df70c8bbc07d8f3c49a491f10433&quot;,
        &quot;Created&quot;: &quot;2017-01-29T10:48:05.1592086Z&quot;,
        &quot;Scope&quot;: &quot;local&quot;,
        &quot;Driver&quot;: &quot;bridge&quot;,
        &quot;EnableIPv6&quot;: false,
        &quot;IPAM&quot;: {
            &quot;Driver&quot;: &quot;default&quot;,
            &quot;Options&quot;: null,
            &quot;Config&quot;: [
                {
                    &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;,
                    &quot;Gateway&quot;: &quot;172.17.0.1&quot; &lt;-- this is what we need
                }
            ]
        },
        &quot;Internal&quot;: false,
        &quot;Attachable&quot;: false,
        &quot;Containers&quot;: {},
        &quot;Options&quot;: {
            &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;,
            &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;,
            &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,
            &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;,
            &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;,
            &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot;
        },
        &quot;Labels&quot;: {}
    }
]
</code></pre><p>What’s important for us is the gateway. In this case, our containers would be spawned with IP addresses from 172.17.0.2</p><p>So now we can start a few containers:</p><pre><code>docker run -e ADVERTISE_ADDR=172.17.0.2 -p 8080:8080 distapp
docker run -e ADVERTISE_ADDR=172.17.0.3 -e CLUSTER_ADDR=172.17.0.2 -p 8081:8080 distapp
docker run -e ADVERTISE_ADDR=172.17.0.4 -e CLUSTER_ADDR=172.17.0.3 -p 8082:8080 distapp
docker run -e ADVERTISE_ADDR=172.17.0.5 -e CLUSTER_ADDR=172.17.0.4 -p 8083:8080 distapp
</code></pre><p>Next on you can test your deployment by stopping and starting containers, and setting/getting the variables at:</p><pre><code>localhost:8080/set/5
localhost:8082/get/5
etc...
</code></pre><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>What’s important, this is a really basic distributed system, it may become inconsistent (if you update the value on two different machines simultaneously, the cluster will have two values depending on the machine).<br>If you want to learn more, read about CAP, consensus, Paxos, RAFT, gossip, and data replication, they are all very interesting topics (at least in my opinion).</p><p>Anyways, I hope you had fun creating a small distributed system and encourage you to build your own, more advanced one, it’ll be a great learning experience for sure!</p><p>The whole code is available on <a href=https://github.com/cube2222/Blog/tree/master/Building%20a%20simple%20distributed%20database>my Github</a>.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://cube2222.github.io/tags/cluster/>cluster</a></li><li><a href=https://cube2222.github.io/tags/database/>database</a></li><li><a href=https://cube2222.github.io/tags/distributed/>distributed</a></li><li><a href=https://cube2222.github.io/tags/go/>go</a></li><li><a href=https://cube2222.github.io/tags/golang/>golang</a></li><li><a href=https://cube2222.github.io/tags/microservice/>microservice</a></li><li><a href=https://cube2222.github.io/tags/microservices/>microservices</a></li><li><a href=https://cube2222.github.io/tags/resiliency/>resiliency</a></li><li><a href=https://cube2222.github.io/tags/server/>server</a></li><li><a href=https://cube2222.github.io/tags/tutorial/>tutorial</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Practical Golang: Building a simple, distributed one-value database with Hashicorp Serf on twitter" href="https://twitter.com/intent/tweet/?text=Practical%20Golang%3a%20Building%20a%20simple%2c%20distributed%20one-value%20database%20with%20Hashicorp%20Serf&url=https%3a%2f%2fcube2222.github.io%2f2017%2f01%2f29%2fpractical-golang-building-a-simple-distributed-one-value-database-with-hashicorp-serf%2f&hashtags=cluster%2cdatabase%2cdistributed%2cgo%2cgolang%2cmicroservice%2cmicroservices%2cresiliency%2cserver%2ctutorial"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Practical Golang: Building a simple, distributed one-value database with Hashicorp Serf on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fcube2222.github.io%2f2017%2f01%2f29%2fpractical-golang-building-a-simple-distributed-one-value-database-with-hashicorp-serf%2f&title=Practical%20Golang%3a%20Building%20a%20simple%2c%20distributed%20one-value%20database%20with%20Hashicorp%20Serf&summary=Practical%20Golang%3a%20Building%20a%20simple%2c%20distributed%20one-value%20database%20with%20Hashicorp%20Serf&source=https%3a%2f%2fcube2222.github.io%2f2017%2f01%2f29%2fpractical-golang-building-a-simple-distributed-one-value-database-with-hashicorp-serf%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Practical Golang: Building a simple, distributed one-value database with Hashicorp Serf on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fcube2222.github.io%2f2017%2f01%2f29%2fpractical-golang-building-a-simple-distributed-one-value-database-with-hashicorp-serf%2f&title=Practical%20Golang%3a%20Building%20a%20simple%2c%20distributed%20one-value%20database%20with%20Hashicorp%20Serf"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Practical Golang: Building a simple, distributed one-value database with Hashicorp Serf on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fcube2222.github.io%2f2017%2f01%2f29%2fpractical-golang-building-a-simple-distributed-one-value-database-with-hashicorp-serf%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Practical Golang: Building a simple, distributed one-value database with Hashicorp Serf on whatsapp" href="https://api.whatsapp.com/send?text=Practical%20Golang%3a%20Building%20a%20simple%2c%20distributed%20one-value%20database%20with%20Hashicorp%20Serf%20-%20https%3a%2f%2fcube2222.github.io%2f2017%2f01%2f29%2fpractical-golang-building-a-simple-distributed-one-value-database-with-hashicorp-serf%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Practical Golang: Building a simple, distributed one-value database with Hashicorp Serf on telegram" href="https://telegram.me/share/url?text=Practical%20Golang%3a%20Building%20a%20simple%2c%20distributed%20one-value%20database%20with%20Hashicorp%20Serf&url=https%3a%2f%2fcube2222.github.io%2f2017%2f01%2f29%2fpractical-golang-building-a-simple-distributed-one-value-database-with-hashicorp-serf%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2021 <a href=https://cube2222.github.io/>Jacob Martin</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>